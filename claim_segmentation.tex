\chapter{Claim segmentation}
\label{chap:claim_segmentation}

Instead of dealing with entire posts as done in chapters~\ref{chap:argclu} and
~\ref{chap:argrec}, here we wish to first segment posts into \emph{atomic units
that convey a single thought} -- \textbf{claims}.
The term claim is used to refer to an \emph{elementary argumentative component}, 
which are a generalization of elementary discourse units
\citep{winter1982towards, givon1983topic, polanyi1996linguistic}
(argumentative units are 
explained in subsection~\ref{subsec:arg_comp_ext}).  Claims as
defined here are not to be confused with claims from Toulmin or Freeman's
argumentation model. Splitting text into argumentative claims is important
because of two main reasons. 
First, non-argumentative content is discarded as it does not 
make statements relevant to the topic
only (even though sometimes that can prove useful as shown by 
\citep{madnani2012identifying}).
Second, the process of claim segmentation results in claims, which are the
basis of subsequent analysis. Extracted claims can then be related to each
other (i.e. \emph{support} or \emph{attack} relations), further specialized to
fit an argument model (i.e. claims are classified into warrants, rebuttals,
etc. stemming from the Toulmin model), directly analyzed (i.e. clustered as
done in chapter~\ref{chap:argclu}), or structured (i.e. to microstructures or
ontological formalizations as explained in chapter~\ref{chap:formalization}).

%The \textbf{claim segmentation task} corresponds to the task of argumentative component
%extraction, more specifically argumentative boundary detection, which is
%explained in subsection~\ref{subsec:arg_comp_ext}. 

% TODO give intro to motivate structure approach
% outline steps of structured approach

\section{Data}

\setlength{\tabcolsep}{4pt}

\begin{table*}[t]
\begin{center}
{\footnotesize
	\begin{tabular}{@{}p{0.2\linewidth} p{0.30\linewidth} p{0.30\linewidth} }
\toprule
\textbf{User post} & \textbf{Claim segment} & \textbf{Claim paraphrase}   \\
\midrule
\multirow{3}{*}{\parbox{3cm}{
		\emph{Men should fall in love with women that's why they where
		created and women should get married to men because it makes
		everything easier. }
}}
&  
\emph{Men should fall in love with women.}
& \emph{People of opposite sex should fall in love.}
\\
\cmidrule{2-3}
& \emph{that's why they where created} & \emph{Men and women are created to pair.}
 \\
\cmidrule{2-3}
& \emph{women should get married to men because it makes everything easier.} & 
 \emph{Heterosexual marriages make everything easier.}
 \\
 \bottomrule
\end{tabular}}
\end{center}
\caption{An example of a user post segmented into three claim segments with
	their correspoding paraphrase.}
\label{tab:claim_seg_post_segments}
\end{table*}

We adopt the dataset of \citet{hasan2014you} which contains 
user posts from online two-sided discussions on a number of issues. 
We consider two topics: ``Gay Rights'' and 
``Marijuana'' and 
sample 100 posts (50 \textbf{pro} and 50 \textbf{con}) from each topic. 
For both topics, we used trained annotators.
First, annotators segment out claims from user posts 
Second, after segmenting out a claim, the annotators provide a paraphrased
version of the claim.
We assume that paraphrasing helps understanding of claims.
% TODO think how to incorpore wyner 
% Our work is similar to \citep{wyner2016working} who use a controlled language 
% for paraphrasing claims. 

Claim segmenting separates argumenative from non-argumentative content. 
There are many ways a post can be segmented into claims in addition to being
a number of ways to paraphrase a claim. 
The ambiguity can be reduced by doing these two tasks jointly. 
The end result paraphrased should be \emph{simplyfing claim paraphrases}: 
paraphrases that provide the essence of claims devoid of 
superflous words and phrases. 
To that end, we adopt nine paraphrasing principles: 
\begin{enumdescript}
\item[Argumentativeness] --- Only argumentative text should paraphrased;
\item[Atomicity] --- A claim should convey a single thought; 
\item[Authority] --- Experts in claims from expert opinion should be made
	explicit in the paraphrase; 
\item[Brevity] --- Paraphrases should keep only the relevant argumentative
	content; 
\item[Canonicity] --- Canonical terms and phrases are preffered over idiomatic
	language; 
\item[Contextuality] --- Claims should be paraphrased by considering their
	local and topical context as well as their context; 
\item[Declarativity] --- paraphrases should be in declarative form; 
\item[Dereferencing] --- Pronouns and nominal references should be resolved; and
\item[Explicitness] --- Only explicitly stated information should be
	paraphrased, and not whatever might be implied by the claim 
\end{enumdescript}
Unlike most previous approaches to argumentative component boundaries, we allow
for both overlapping and discontiguous segments.  Full annotation guidelines
are in appendix~\ref{sec:argseg_annotation}. The annotation for ``Gay Rights''
was carried out by one trained annotator and took 25 hours.
The annotation for ``Marijuana'' was carried out by three annotators. 
The 100 user posts yield 920 claim segments for ``Gay rights'', as did the 100 
user posts in ``Marijuana''. 
Table~\ref{tab:claim_seg_post_segments} gives an example of a post from
an online discussion split into segmented and paraphrased claims. 
For the ``Gay Rights'' topic, the segments covered 79.6\% of the text, while the remaining
20.4\% may be considered non-argumentative. The ``Marijuana'' topic contained 
more argumentative text, as 88.98\% of text is covered by argumentative 
segments, while 11.02\% was annotated as non-argumentative. 

% \noindent - dataset statistics \\
% - how many examples are overlapping \\

\section{Problem Formulation}
\begin{table}
\centering
\begin{tabular}{c| c c}
 i & $x_i$ & $Y_i$ \\
\midrule
 1& marijuana & $\{1 \}$ \\
 2& is & $\{ 1 \}$ \\
 3& believed &  $\{ 1 \}$ \\
 4& to& $\{ 1 \}$ \\
 5& be& $\{ 1 \}$ \\
 6& a& $\{ 1 \}$ \\
7 & stepping& $\{ 1 \}$ \\
8 & -& $\{ 1 \}$
\end{tabular}
\hfill
\begin{tabular}{c | c c}
 i & $x_i$ & $Y_i$ \\
\midrule
9 & stone& $\{ 1 \}$ \\
10& drug& $\{ 1 \} $ \\
11& that& $\{2, 3, 4\}$ \\
12& can& $\{2, 3, 4\}$ \\
13& eventually& $\{2, 3, 4\}$ \\
14& lead& $\{2, 3, 4\}$ \\
15& to& $\{2, 3, 4\}$ \\
16& addiction& $\{2, 3, 4\}$ \\
\end{tabular}
\hfill
\begin{tabular}{c| c c}
 i & $x_i$ & $Y_i$ \\
\midrule
17 & to& $\{2, 3, 4\}$ \\
18 & heroin & $\{ 2 \}$ \\
19 & , & $\{2\}$ \\
20 & cocaine& $\{3 \}$ \\
21 & and& $\{ \}$ \\
22 & other& $\{ 4 \} $\\
23 & harder& $\{ 4 \} $\\
24 & drugs& $\{ 4 \} $\\
\end{tabular}
\caption{An example post from the ``Marijuana'' topic. Each token of the post 
	is assigned a set of labels. Segments $2, 3, 4$ overlap on tokens 10-17. 
	Segments $3$ and $4$ are discontiguous.}
\label{tab:multilabel_segment_example}
\end{table}


\begin{figure}
\scriptsize
\begin{tabular}{l | ccccccc cccccccc ccc ccccc}
	& Nothing& can& bring& peace& to& this& world 
&Its& a& great& idea& to& try& and& push& 
for& world& peace 
	& but & it & will & never & happen \\
	\midrule
	\texttt{BIO} & \texttt{B} & \texttt{I} & \texttt{I} &
	\texttt{I} & \texttt{I} & \texttt{I} & \texttt{I} & \texttt{B}&
	\texttt{I} & \texttt{I} & \texttt{I} & \texttt{I} & \texttt{I} &
	\texttt{I} & \texttt{I} & \texttt{I} & \texttt{I} & \texttt{I} &
	\texttt{B} & \texttt{I} & \texttt{I} & \texttt{I} & \texttt{I} \\
	\midrule
	\multirow{3}{*}{ML} & 1 & 1 & 1 & 1 & 1 & 1 & 1 
	& 0& 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 
	& 0 & 0 & 0 & 0 & 0 \\

	& 0 & 0 & 0 & 0 & 0 & 0 & 0 
	& 1& 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 
	& 0 & 0 & 0 & 0 & 0 \\

	& 0 & 0 & 0 & 0 & 0 & 0 & 0 
	& 0& 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 
	& 1 & 1 & 1 & 1 & 1 \\

\end{tabular}
	\caption{Multilabel (ML) and \texttt{BIO} labelling of post with three segments: 
	``\textit{Nothing can bring peace to this world}'', 
	``\textit{Its a great idea to try and push for world peace}'', and
	``\textit{but it will never happen}''. 
}
\label{fig:segment_example_bio_multilabel}
\end{figure}

Now, since the dataset is defined, we will mathematically formalize this
problem.  Let $\mathbf{x} = (x_1, \dots, x_N)$ represent a sentence of size $N$
as a vector of tokens where the index represents the position of the word in
the sentence.  Then $\mathbf{Y} = (Y_1, \dots, Y_N)$ is a vector where each
element represents a set of labels.  Each $Y_i, i \in \{1, \dots, N\}$ is a set
of labels denoting which segment the the token belongs to.  As an example, the
post(comment) ``\textit{ Marijuana is believed to be a stepping-stone drug that
can eventually lead to addiction to heroin, cocaine and other harder
% TODO actually is 25 tokens
drugs.}'' is tokenized into 24 tokens with respective $X$ and $Y$ shown in
table ~\ref{tab:multilabel_segment_example}. 
Mapping $x$ to $Y$ can be framed as multilabel classification since
each $y \in Y$ can contain up to $N$ labels, yielding a total of $2^{N}$ 
possible combinations per element. 
This problem can now be framed as multilabel classification 
(multilabel classification described in section \ref{sec:chain_classification}). 
If it is framed using the binary relevance setup there is
an exponential number of possible solutions, which makes efficient search 
of possible solutions expensive. 
The third row of figure~\ref{fig:segment_example_bio_multilabel} shows how a
multilabel labeling of segments would be on a post from the ``Marijuana''
topic. 

Alternatively to multilabel classification, a number of approaches have been
explored. Looking at sequence extraction in other areas of information
extraction, problems of shallow parsing \citep{sha2003shallow} and named entity
recognition \citep{nadeau2007survey} stand out.  \citet{sha2003shallow}
employed \texttt{BIO} encoding for shallow parsing and used conditional random
fields as one of the first structured prediction approaches to information
extraction.  \texttt{BIO} labels indicate whether the word is outside a segment
(\texttt{O}), starts a segment (\texttt{B}) or continues a segment
(\texttt{I}).  In order to apply \texttt{BIO} labeling, the final segments
\emph{must} be non-overlapping and contigious. 
Row 2 of figure ~\ref{fig:segment_example_bio_multilabel} shows a
post from the ``Marijuana'' topic 
containing three segments labeled with \texttt{BIO} tags. 
Using \texttt{BIO} tags instead of applying the multilabel approach
simplifies solving the sequence extraction by 
having to predict only a single label per token, which makes the number of solutions 
for each $x$ go down from $2^{N}$ to $|\{B, I, O\}|$. 

But, when the segments are overlapping or discontiguous using \texttt{BIO} tags
can't be used to bijectively encode segments of labels. 
To tackle overlapping and/or discontiguous segments a number of approaches have been
proposed, mostly
in the area of named entity recognition on the analysis of clinical texts, 
on datasets such as BioInfer \citep{pyysalo2007bioinfer}. 
\citet{byrne2007nested} proposed a solution for 
extracting non-overlapping contigious entities which uses
tag n-grams instead of words. Working to also solve 
non-overlapping contigious entities 
\citep{alex2007recognising} propose using multiple-layer tagging. 
Also in an effort to try and extrat non-overlapping contigious entities
\citet{finkel2009nested} treated entity recognition as a parsing task
and adopted common state machine parsing approaches. 
More recently, there has been renewed interesting in solving 
the problem of extracting overlapping and contigious named
entities as part of the 
the SemEval-2014 analysis of clinical texts competition
\citep{pradhan2014semeval}.
One of the tasks in the compentition was named entity recognition of medical 
entities, which involved both discontiguous and overlapping entities. 
Out of all submissions, only two systems produced solutions that 
 could handle both 
discontiguous and overlapping entities. 
The first system, described in \citep{pathak2014ezdi}, uses
a standard \texttt{BIO} tagging pipelined 
with SVMs to combine resulting spans. 
Whereas the second system, described in \citep{zhang2014uth_ccb}, expands 
on the regular \texttt{BIO} tagset. 
They propose to tag each token with one of \textbf{B}, \textbf{I},
\textbf{O}, \textbf{BD}, \textbf{ID}, \textbf{BH}, and
\textbf{IH} which denote \textbf{B}eggining of entity, \textbf{I}nside entity, \textbf{O}utside
of entity, \textbf{B}eginning of 
\textbf{D}iscontigious entity, \textbf{I}nside of \textbf{D}iscontigious entity,
\textbf{B}eginning of \textbf{H}ead, and
\textbf{I}nside of \textbf{H}ead. 
However, this encoding is lossy, which makes decoding ambigous in some cases. 
Furthermore, using this encoding may produce invalid sequences of tags. 
Apart from this work, this expanded \texttt{BIO} encoding 
was used in \citep{muis2018learning} where they proposed
a hypergraph-based model to solve the clinical named entity challenge. 
A thorough survey on extracting overlapping and discontiguous named entities can 
be found in \citep{dai2018recognizing}. They consider all tag encodings and 
recommend  multilabel encoding as the most efficient one, as it 
doesn't lose any information, which we agree with. 

The clinical named entity extraction problem and semantic parsing are
equivalent to the claim segmentation problem. 
Both problems are usually framed as sequence labeling problems. Thus we frame 
claim segmentation as a sequence labeling problem. 
Based on related work on named entity recognition, to encode labels for tokens we consider
two approaches: multilabel and \texttt{BIO} approach since both
are nonambigous. 
The multilabel approach can handle both discontiguous and overlapping entities, but 
has a much wider (exponential) solution space
On the other hand, the \texttt{BIO} tagging approach has a linear search space, but 
we will only focus on 
predicting segments which aren't discontiguous or overlapping.
A comparison of the \texttt{BIO} and multilabel token labeling for a post divided
into claim segments is shown in 
figure~\ref{fig:segment_example_bio_multilabel} and an example of a post with overlapping
and discontiguous segments in shown in table~\ref{tab:multilabel_segment_example}.

\begin{figure}
\scriptsize
\begin{tikzpicture}[node distance=1mm]
\node (s1) {Marijuana is believed to be a stepping-stone drug};
\node (s234) [right=of s1]{that can eventually lead to additiction to};
	\node (s2) [right=of s234]{heroin\textcolor{white}{y}};
	\node (s3) [right=of s2.east]{cocaine\textcolor{white}{y}};
	\node (o) [right=of s3] {and\textcolor{white}{y}};
	\node (s4) [right=of o] {other\textcolor{white}{y}harder drugs.};

\node (s1lab) [below=of s1] {\textcolor{red}{Segment 1}};
\node (s2lab) [below=of s2, xshift=-1.7cm, yshift=-2.5mm] {\textcolor{blue}{Segment 2}};
\node (s3lab) [below left=1cm of s3, xshift=1mm, yshift=-1mm] {\textcolor{green}{Segment 3}};
\node (s4lab1) [below=of s234, xshift=-0.6cm, yshift=1mm] {\textcolor{orangegreen}{Segment 4}};
\node (s4lab2) [below=of s4] {\textcolor{orangegreen}{Segment 4}};

\draw [-]
($(s1.east) - (0.5mm, 0)$)
-- ++(0, -.2)
-| ($(s1.west) $);

% S4 segment
\draw [-]
($(s234.east) $)
-- ++(0, -0.2)
-| ($(s234.west) - (0, 0) $);

% S2 segment
\draw [-]
($(s234.west) - (0.5mm, 0)$)
-- ++(0, -0.6)
	-| ($(s2.east) - (0.5mm, 0) $);

% S3 segment
\draw [-]
($(s234.west) - (1mm, 0)$)
-- ++(0, -1.0)
-| ($(s3.east) $);

% other S4 segment
\draw [-]
($(s4.west) $)
-- ++(0, -.2)
-| ($(s4.east) $);
\end{tikzpicture}
	\caption{An example of post made in the ``Marijuana'' topic. 
	\textcolor{red}{Segment 1} is a regular segment. 
	\textcolor{blue}{Segment 2} and \textcolor{green}{Segment 3} are mutually overlapping.
	\textcolor{orangegreen}{Segment 4} is both overlapping and discontiguous.}
	\label{fig:segment_example_range}
\end{figure}

%'<S1>Marijuana is believed to be a stepping-stone drug
%</S1><S2><S3><S4>that can eventually lead to addiction to
%</S3></S4>heroin,</S2><S3> cocaine</S3> and<S4> other harder
%drugs.</S4>'

% <S1>Nothing can bring peace to this earth.</S1> <S2>Its a great idea to try and
% push for world peace</S2> <S3>but it will never happen...</S3>'


\begin{figure}
\begin{algorithmic}[1]
\Function{is\_punctuation}{ch}
\If{$ch = ``." \cup ch = ``?" \cup ch = ``!"$}
\State
\Return $\mathit{True}$
\Else
\State
\Return $\mathit{False}$
\EndIf
%\Return $out$
\EndFunction

\State
\State 

\State \textbf{INPUT} $\mathit{text}$
\State $\mathit{seg\_id} \gets 1$
\State $Y[\mathit{seg\_id}] \gets \emptyset$
\ForAll{$i \in |\mathit{text}|$}
	\State $token \gets text[i]$
	\State $Y[\mathit{seg\_id}] \gets Y[\mathit{seg\_id}] \cup \mathit{token}$
	\State
	\If{$\mathit{IS\_PUNCTUATION}(\mathit{token}) \cap i \neq 0$}
	\State $\mathit{seg\_id} \gets \mathit{seg\_id} + 1$
	\EndIf
\EndFor
\State
\Return $Y$
\end{algorithmic}
\caption{Claim segmentation punctuation based heuristic.
Input is a list of tokens, outputs a nested list of lists, where 
each list corresponds to a segment. 
None of the tokens is declared as non-argumentative.
The \texttt{IS\_PUNCTUATION} function has been simplified for readability
purposes. 
	}
\label{alg:heuristic_claimseg}
\end{figure}

\section{Models}

We frame the claim segmentation problem as a supervised learning token-level 
classification \citep{ajjour2017unit}. 
To label tokens, we use one of two 
token-level tagging solutions. 
First, we adopt the multilabel classification (\texttt{ML}) approach, where
each token can belong to zero or more segments. For the second (\texttt{BIO}) approach, 
we discard overlapping and non-contigious segments and then apply
standard \texttt{BIO} labels. 
After applying the tagging to data, we propose three models to 
solve the claim segmentation problems. First, we apply a classic approach 
from argumentation mining literature where each sentence is treated as a segment. 
Second, we use n-gram features as input to a SVM. 
Finally, we combine deep learning and structured prediction.

\paragraph{Na\"ive Heuristic. } 
Our baseline model is extremely similar to most approaches in argumentation mining: 
each sentence is a claim segment \citep{rooney2012applying, stab2014identifying}.
We adopt a similar approach, where we simply assume punctuation is a strong
indication a new claim starts. However, unlike 
other work we  make each sentence argumentative (which we deem reasonable
assumption given that a large portion of the dataset is argumentative)
For each post (comment), we simply iterate through all tokens
and start a new claim when a token equals a punctuation mark. 
This is essentially similar to sentence segmentation \citep{palmer2000tokenisation}. 
The heuristic is outlined in algorithm~\ref{alg:heuristic_claimseg}. 
An example of how the algorithm works for a post is shown in
table~\ref{tab:heuristic_example}. 

\begin{table}[t]
\begin{tabular}{@{}p{0.5\linewidth} p{0.50\linewidth}}
\toprule
\multirow{7}{*}{
\parbox{7cm}{
\textit{if we legalize pot there wil be a sharp increase in 
demand and consumption over a period of time
then............it will start to decline....slowly at first until
smoking pot becomes drinking wine.......only on special
occasions........... that's why we should continue the war
it's not like weed is damn near impossible to obtain ...... in my
opinion there is no war ....... there never was ...}
}}
		& \emph{if we legalize pot there wil be a sharp increase in 
demand and consumption over a period of time
	then ............} \\ \cline{2-2}
		& \emph{it will start to decline .... } \\ \cline{2-2}
		& \emph{slowly at first until
	smoking pot becomes drinking wine .......} \\  \cline{2-2} 
	& \emph{
only on special
occasions
...........
		} \\  \cline{2-2}
	& \emph{
that's why we should continue the war
it's not like weed is damn near impossible to obtain ......
		} \\\cline{2-2}
	& \emph{
in my
opinion there is no war .......
} \\\cline{2-2}
	& \emph{
there never was ...
} \\
\bottomrule
	\caption{Example of heuristic algorithm output. }
\label{tab:heuristic_example}
\end{tabular}
\end{table}

\paragraph{SVM. } We use a weighted SVM for the second approach. Weights are 
calculated to compensate for the class disbalance 
by weighing less prominent class examples with the ratio of number of 
dominant class vs. recesive class examples in the training set. 
To train the model, we use $5 \times 3$ nested-cross validation
When trying the multilabel approach, features  
training examples by taking a word with a
configurable context window (of surrounding words). 
For features, we use calculate tf-idf and 
distributed word representations 
(fasttext\footnote{https://fasttext.cc/})
and word2vec\footnote{https://code.google.com/archive/p/word2vec/}
pretrained vectors).

\paragraph{BiLSTM + CRF Model.}
Finally, we try combining deep learning (BiLSTM) and structured prediction
(CRF). 
The general idea of a BiLSTM + CRF model is described in
subsection~\ref{subsec:lstm_crf}.  We make a few minor modifications in our
model. 
Our model works in two stages. In the first stage, a BiLSTM is used to
encode a sequence of tokens. The BiLSTM produces pairs of hidden states and
outputs. The
outputs of the BiLSTM are then fed into a feed-forward linear layer which maps
the BiLSTM output to the label probability space. In the second stage, the
output of the BiLSTM is used as features for the CRF.  
The CRF uses the input features and its state transition matrix to efficiently
use past and future tags to predict the current tag. The viterbi algorithm
(described in subsection~\ref{sec:viterbi}) is used 
to efficiently compute optimal tag sequences. 
We use negative log likelihood as the loss function. We train and evaluate the model
using 5-fold cross-validation. 

The parameters of the model are paramaters of the BiLSTM, linear layer, and
state transition matrix of the CRF. As for the hyperparameters of the model, 
we use 200 feed forward units, set the word embedding size to 300, and
use a single layer bidirectional LSTM to encode sequences. 
We consider both using pretrained word embeddings
and training embeddings from scratch. Furthermore, we experiment by enabling
and disabling fine-tunning of input embeddings when using pretrained
word embeddings. We experiment with both multilabel and \texttt{BIO} tags. 
In the multilabel setup, we attempt to share the transition matrix across
different when training across segments. 

The reason we opt for this model is two fold. First, BiLSTMs have previously
been successfully used in argumentation mining \citep{habernal2016argument}. 
Second, the combination of a BiLSTM with a CRF is considered an extremely strong baseline
(and often proves as a topline) for sequence tagging problems
\citep{huang2015bidirectional}.


\section{Experiments}

\begin{figure}
\begin{algorithmic}[1]
\State \textbf{INPUT} $\mathit{predicted}, \mathit{true}, \mathit{offset}$
\State $\mathit{found} \gets \{\}$
\State
\ForAll{$i \in |\mathit{true}|$}
  \ForAll{$j \in |\mathit{predicted}|$}
	\State $\mathit{common} \gets $\texttt{LCS\_LENGTH}$(\mathit{true}[i], \mathit{predicted}[j])$
	\State
	\State $\mathit{is\_smaller\_than\_offset} \gets |\mathit{predicted}[j]| > \mathit{offset}$
	\State $\mathit{is\_common\_enough} \gets $ $|\mathit{predicted}[j]| -
	\mathit{common} \leq \mathit{offset}$
	\State $\mathit{has\_small\_size\_diff} \gets |\mathit{predicted}[j]| -
	|\mathit{true}[i]| \leq \mathit{offset}$
	\State
	\If{$\mathit{is\_smaller\_than\_offset} \cap 
	\mathit{is\_common\_enough} \cap \mathit{has\_small\_size\_diff}$}
	  \State $\mathit{found} \gets \mathit{found} \cup \mathit{true}[i]$
	  \State \textbf{break}
	\EndIf
  \EndFor
\EndFor
\State 
\State $\mathit{precision} \gets \frac{|found|}{|true|}$
\end{algorithmic}
\caption{Algorithm to calculate precision with arbitrary offset between 
	two sets of segments, each segment being a list of tokens.
	\texttt{LCS\_LENGTH} calculates the length of the 
	longest common subsequence of two sequences.  
	We use a solution presented in
	\citep{hunt1977fast}.
	Recall is equivalently calculated, but with different inputs. 
	}
\label{alg:precision_offset}
\end{figure}

We compare the models using two main set of metrics. The first set of 
metrics is standard when evaluating information extraction problems.
We measure precision, recall, and f1-score of the retrieved segments, 
which we denote with P, R and F1 respectively. 
Also, since we're dealing with sequences, we use the standard metrics, but 
we allow for mistakes of arbitrary length. This means that a retrieved segment which
has one extra token will count as correctly retrieved. This method is outlined in 
figure~\ref{alg:precision_offset}. 
The measure indicates when the extracted segment is close to the desired one,
since having exact segments might not always be important, for example: the
post ``\emph{Nothing can bring peace to this earth. Its a great idea to try and
push for world peace, but it will never happen...}'' contains three segments,
one of them being ``\emph{but it will never happen...}'', but if the produced output is
``\textit{world peace but it will never happen...} and the allowed offset is two or more
this will be counted as correct. We can even see that in this example it might be useful 
to have additional information in the segment since it provides additional 
context.
The reported results use the allowed offset of two and denote precision,
recall, and F1 score with offset as oP, oR and oF1 respectively.

\begin{table}
	\centering
\begingroup
\setlength{\tabcolsep}{10pt} % Default value: 6pt
\renewcommand{\arraystretch}{1.5} % Default value: 1
	\begin{tabular}{l c  c c c c c c}
\toprule
		Tagset & Model & P & R & F1 & oP & oR & oF1 \\
      \midrule
		& Heuristic    & \textbf{0.41} & \textbf{0.23} & \textbf{0.29} &
		\textbf{0.89} & 0.49 & \textbf{0.63} \\
		\cline{2-8}
		\multirow{2}{*}{Multilabel } & SVM & & & & & & \\
		& BiLSTM + CRF & 0.12 & 0.01 & 0.02 & 0.32 & 0.04 & 0.06\\
		\cline{2-8}
		\multirow{2}{*}{\texttt{BIO}} & SVM & & & & & & \\

		& BiLSTM + CRF & 0.32 & 0.22 & 0.26 & 0.63 & \textbf{0.57} & 0.60 \\
      \bottomrule
	\end{tabular}
	\endgroup
	\caption{Claim segmentation standard and offset (set to two) precision, recall, 
	and F1 score in the multilabel and \texttt{BIO} setups. }
	\label{tab:claim_seg_results}
\end{table}

First, we wish to compare the three proposed approaches: 
the simple heuristic, the SVM approach, and the BiLSTM+CRF approach
in terms of both standard and offset precision, recall, and f-1 score.
In both the SVM and BiLSTM+CRF approach, we use multilabel encoding. 
In the CRF approach, we don't share the transition table across 
segments and train embeddings from scratch.
Results are in table~\ref{tab:claim_seg_results}. 
The results clearly show that the simple heuristic model significantly outperforms
both the SVM and BiLSTM+CRF model which use multilabel encoding. 
This suggests that multilabel encoding where no information across
labels isn't used does not produce feasible solutions. 
To improve the results, we also attempt to fine tune pretrained embeddings and
share the transition table in the BiLSTM+CRF setup, but all of this does not
improve significantly performance, therefore we omit those results.  

Next, since multilabel encoding does seem as a viable solution, we explore the
\texttt{BIO} encoding. In order to do so, we first need to apply label the
dataset using \texttt{BIO} tags. Applying the \texttt{BIO} tagset overlapping
and discontiguous claims are discarded. Now, the topline precision, recall, and 
F1-score are $1.0$, $0.74$, and $0.84$ F1-score. 
Now, we again train the BiLSTM+CRF model. 
This time, we end up with comparable results with the heuristic baseline, as
shown in the final row of table~\ref{tab:claim_seg_results}. 
Based on these results, we therefore conclude that claim segmentation can be solved
reasonably well using  simple heuristic. However, advancing beyond simple heuristics seems
difficult as more advanced models failed to capture how claims are split, particularly
in the case of discontiguous and overlapping claim segments. 

Now, that we have explored
the claim segmentation problem, we will wish to do the next stage in the argumentation mining
pipeline: argumentative structure prediction. 

% 110 # precision basic 208 509 0.4086444007858546                                                                                                                                                                   
% 111 # recall basic 208 921 0.2258414766558089                                                                                                                                                                      
% 112 # offset 452 509 0.888015717092338                                                                                                                                                                             
% 113 # offset 452 921 0.49077090119435396                                                                                                                                                                           

% # separate classifiers, non shared transitions
% # precision basic 31 288 
% # recall basic 30 921
% 
% # joined classifiers, non shared transitions
% # precision basic 28 203
% # recall basic 27 921

% BiLSTM with offset
% # offset 528 838
% # offset 528 921
% 
% # epoch = 25
% # precision 204 / 641
% # recall 204 921

